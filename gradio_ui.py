import gradio as gr
import pandas as pd
import numpy as np
from datetime import datetime
import re
import os
from pathlib import Path
from PIL import Image

# LangChain imports
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.document_loaders import CSVLoader, TextLoader
from langchain.schema import Document
from langchain.chains import RetrievalQA
from langchain.llms.base import LLM
from langchain.callbacks.manager import CallbackManagerForLLMRun
from typing import Optional, List, Any, Dict

# Transformers for Qwen2-VL
from transformers import Qwen2VLForConditionalGeneration, AutoTokenizer, AutoProcessor
from qwen_vl_utils import process_vision_info
import torch

class Qwen2VLLLM:
    def __init__(self):
        super().__init__()
        print("üîÑ ƒêang t·∫£i m√¥ h√¨nh...")
        self.model = Qwen2VLForConditionalGeneration.from_pretrained(
            "Qwen/Qwen2-VL-2B-Instruct", 
            torch_dtype="auto", 
            device_map="auto"
        )
        self.processor = AutoProcessor.from_pretrained("Qwen/Qwen2-VL-2B-Instruct")
        print("‚úÖ M√¥ h√¨nh ƒë√£ s·∫µn s√†ng!")
    
    @property
    def _llm_type(self) -> str:
        return "qwen2vl"
    
    def _call(
        self,
        prompt: str,
        stop: Optional[List[str]] = None,
        run_manager: Optional[CallbackManagerForLLMRun] = None,
        **kwargs: Any,
    ) -> str:
        try:
            messages = [
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt}
                    ]
                }
            ]
            
            text = self.processor.apply_chat_template(
                messages, tokenize=False, add_generation_prompt=True
            )
            
            inputs = self.processor(
                text=[text],
                images=None,
                padding=True,
                return_tensors="pt"
            )
            for key in inputs:
                inputs[key] = inputs[key].to(self.model.device)
                
            
            with torch.no_grad():
                generated_ids = self.model.generate(
                    **inputs,
                    max_new_tokens=512,
                    temperature=0.1,
                    do_sample=True
                )
            
            generated_ids_trimmed = [
                out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
            ]
            
            output_text = self.processor.batch_decode(
                generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False
            )[0]
            
            return output_text
            
        except Exception as e:
            return f"L·ªói: {str(e)}"
    
    def analyze_image_with_text(self, image_path: str, question: str) -> str:
        try:
            image = Image.open(image_path)
            
            messages = [
                {
                    "role": "user",
                    "content": [
                        {"type": "image", "image": image_path},
                        {"type": "text", "text": f"Ph√¢n t√≠ch ·∫£nh n√†y v√† tr·∫£ l·ªùi: {question}. Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát."}
                    ]
                }
            ]
            
            text = self.processor.apply_chat_template(
                messages, tokenize=False, add_generation_prompt=True
            )
            
            inputs = self.processor(
                text=[text],
                images=[image],
                padding=True,
                return_tensors="pt"
            )
            
            with torch.no_grad():
                generated_ids = self.model.generate(
                    **inputs,
                    max_new_tokens=512,
                    temperature=0.1,
                    do_sample=True
                )
            
            generated_ids_trimmed = [
                out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
            ]
            
            output_text = self.processor.batch_decode(
                generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False
            )[0]
            
            return output_text
            
        except Exception as e:
            return f"L·ªói khi ph√¢n t√≠ch ·∫£nh: {str(e)}"

    def classify_question(self, question: str) -> str:
        """Ph√¢n lo·∫°i c√¢u h·ªèi ƒë·ªÉ x√°c ƒë·ªãnh c√≥ c·∫ßn ph√¢n t√≠ch ·∫£nh hay kh√¥ng"""
        
        # T·ª´ kh√≥a li√™n quan ƒë·∫øn ·∫£nh/bi·ªÉu ƒë·ªì/dashboard
        image_keywords = [
            '·∫£nh', 'h√¨nh', 'bi·ªÉu ƒë·ªì', 'chart', 'dashboard', 'm√†n h√¨nh', 'giao di·ªán',
            'nh√¨n th·∫•y', 'hi·ªÉn th·ªã', 'trong ·∫£nh', 'tr√™n ·∫£nh', '·ªü ·∫£nh', 't·ª´ ·∫£nh',
            'm√†u s·∫Øc', 'ƒë·ªì th·ªã', 'visualization', 'visual', 'screen', 'interface',
            'layout', 'design', 'ui', 'ux', 'screenshot'
        ]
        
        # T·ª´ kh√≥a li√™n quan ƒë·∫øn d·ªØ li·ªáu s·ªë
        data_keywords = [
            's·ªë li·ªáu', 'd·ªØ li·ªáu', 'data', 'volume', 'target', 'doanh thu', 'revenue',
            't·ªïng', 'sum', 'average', 'trung b√¨nh', 'th·ªëng k√™', 'ph√¢n t√≠ch s·ªë',
            'bu', 'ƒë∆°n v·ªã', 'kh·ªëi l∆∞·ª£ng', 'percentage', 'ph·∫ßn trƒÉm', '%',
            't√≠nh to√°n', 'calculate', 'count', 'ƒë·∫øm', 'so s√°nh', 'compare'
        ]
        
        question_lower = question.lower()
        
        # ƒê·∫øm s·ªë t·ª´ kh√≥a xu·∫•t hi·ªán
        image_score = sum(1 for keyword in image_keywords if keyword in question_lower)
        data_score = sum(1 for keyword in data_keywords if keyword in question_lower)
        
        # Quy·∫øt ƒë·ªãnh d·ª±a tr√™n score
        if image_score > data_score:
            return "image"
        elif data_score > image_score:
            return "data"
        else:
            # N·∫øu kh√¥ng r√µ r√†ng, ∆∞u ti√™n data
            return "data"

class QASystem:
    def __init__(self):
        print("üöÄ Kh·ªüi t·∫°o QA System...")
        
        self.llm = Qwen2VLLLM()
        
        self.embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-MiniLM-L6-v2"
        )
        
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len,
        )
        
        self.daily_report_data = None
        self.raw_data = None
        self.vector_store = None
        self.current_image_path = "data/test1.png"  # Default image path
        
        self.load_initial_data()
        print("‚úÖ QA System s·∫µn s√†ng!")
    
    def load_initial_data(self):
        """T·∫£i t·∫•t c·∫£ d·ªØ li·ªáu c√≥ s·∫µn khi kh·ªüi ch·∫°y"""
        try:
            # Load daily report
            daily_report_path = "data/daily_report_20250628.csv"
            if os.path.exists(daily_report_path):
                self.daily_report_data = pd.read_csv(daily_report_path)
                print(f"‚úÖ ƒê√£ t·∫£i daily report: {len(self.daily_report_data)} d√≤ng")
            else:
                print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y daily report")
            
            # Load raw data (demotest1.csv)
            raw_data_path = "data/demotest1.csv"
            if os.path.exists(raw_data_path):
                self.raw_data = pd.read_csv(raw_data_path)
                print(f"‚úÖ ƒê√£ t·∫£i raw data: {len(self.raw_data)} d√≤ng")
            else:
                print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y raw data")
            
            # Verify image path
            if os.path.exists(self.current_image_path):
                print("‚úÖ ƒê√£ t√¨m th·∫•y ·∫£nh dashboard")
            else:
                print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y ·∫£nh dashboard")
                # Fallback to old path if exists
                if os.path.exists("test1.png"):
                    self.current_image_path = "test1.png"
                    print("‚úÖ S·ª≠ d·ª•ng ·∫£nh m·∫∑c ƒë·ªãnh test1.png")
            
            # Build vector store if any data is loaded
            if self.daily_report_data is not None or self.raw_data is not None:
                self.build_vector_store()
                
        except Exception as e:
            print(f"‚ùå L·ªói khi t·∫£i d·ªØ li·ªáu ban ƒë·∫ßu: {e}")
    
    def get_data_summary(self) -> str:
        """T·∫°o summary v·ªÅ d·ªØ li·ªáu hi·ªán c√≥"""
        summary_parts = []
        
        if self.daily_report_data is not None:
            total_volume = self.daily_report_data['volume'].sum() if 'volume' in self.daily_report_data.columns else 0
            total_bu = len(self.daily_report_data)
            summary_parts.append(f"üìä **Daily Report**: {total_bu} BU, t·ªïng volume: {total_volume:,.0f}")
        
        if self.raw_data is not None:
            total_records = len(self.raw_data)
            if 'vol_sellout_kat' in self.raw_data.columns:
                total_sellout = self.raw_data['vol_sellout_kat'].sum()
                summary_parts.append(f"üìà **Raw Data**: {total_records:,} records, t·ªïng sellout: {total_sellout:,.0f}")
            else:
                summary_parts.append(f"üìà **Raw Data**: {total_records:,} records")
        
        if os.path.exists(self.current_image_path):
            summary_parts.append(f"üñºÔ∏è **Dashboard**: {os.path.basename(self.current_image_path)}")
        
        if not summary_parts:
            return "‚ùå Ch∆∞a c√≥ d·ªØ li·ªáu n√†o ƒë∆∞·ª£c t·∫£i"
        
        return "\n".join(summary_parts)
    
    def process_csv_file(self, file_path: str, is_raw_data: bool = False):
        try:
            df = pd.read_csv(file_path)
            if is_raw_data:
                self.raw_data = df
            else:
                self.daily_report_data = df
            
            self.build_vector_store()
            return f"‚úÖ ƒê√£ t·∫£i CSV th√†nh c√¥ng ({len(df)} d√≤ng)"
            
        except Exception as e:
            return f"‚ùå L·ªói: {str(e)}"
    
    def process_image(self, image_path: str):
        """X·ª≠ l√Ω ·∫£nh ƒë∆∞·ª£c upload"""
        try:
            if image_path and os.path.exists(image_path):
                self.current_image_path = image_path
                return f"‚úÖ ƒê√£ t·∫£i ·∫£nh th√†nh c√¥ng", image_path
            else:
                return "‚ùå Kh√¥ng t√¨m th·∫•y ·∫£nh", None
        except Exception as e:
            return f"‚ùå L·ªói: {str(e)}", None
    
    def build_vector_store(self):
        try:
            documents = []
            
            if self.daily_report_data is not None:
                daily_text = f"D·ªØ li·ªáu Daily Report:\nC√°c c·ªôt: {', '.join(self.daily_report_data.columns.tolist())}\n"
                
                for _, row in self.daily_report_data.iterrows():
                    bu_text = f"ƒê∆°n v·ªã {row['BU']} (M√£: {row['BU_CODE']}): "
                    bu_text += f"Kh·ªëi l∆∞·ª£ng: {row['volume']}, "
                    bu_text += f"Target MK: {row['target_mk_volume']}, Target SK: {row['target_sk_volume']}, "
                    bu_text += f"Volume MK: {row['volume_MK']}, Volume SK: {row['volume_SK']}, "
                    bu_text += f"% MK: {row['%_mk_done']}%, % SK: {row['%_sk_done']}%"
                    
                    documents.append(Document(
                        page_content=bu_text,
                        metadata={"source": f"daily_{row['BU_CODE']}", "type": "daily"}
                    ))
                
                documents.append(Document(
                    page_content=daily_text,
                    metadata={"source": "daily_summary", "type": "summary"}
                ))
            
            if self.raw_data is not None:
                raw_text = f"D·ªØ li·ªáu chi ti·∫øt:\nC√°c c·ªôt: {', '.join(self.raw_data.columns.tolist())}\n"
                
                if 'bu_name' in self.raw_data.columns:
                    bu_summary = self.raw_data.groupby('bu_name').agg({
                        'vol_sellout_kat': 'sum',
                        'rev_sellout_kat_vat': 'sum'
                    }).reset_index()
                    
                    for _, row in bu_summary.iterrows():
                        bu_detail = f"ƒê∆°n v·ªã {row['bu_name']}: "
                        bu_detail += f"Volume: {row['vol_sellout_kat']}, "
                        bu_detail += f"Doanh thu: {row['rev_sellout_kat_vat']}"
                        
                        documents.append(Document(
                            page_content=bu_detail,
                            metadata={"source": f"raw_{row['bu_name']}", "type": "raw"}
                        ))
                
                documents.append(Document(
                    page_content=raw_text,
                    metadata={"source": "raw_summary", "type": "summary"}
                ))
            
            if documents:
                split_documents = self.text_splitter.split_documents(documents)
                self.vector_store = FAISS.from_documents(split_documents, self.embeddings)
                print(f"‚úÖ Vector store: {len(split_documents)} chunks")
                
        except Exception as e:
            print(f"L·ªói vector store: {e}")
    
    def answer_question(self, question: str) -> str:
        """Tr·∫£ l·ªùi c√¢u h·ªèi v·ªõi logic ph√¢n lo·∫°i th√¥ng minh"""
        try:
            # Ph√¢n lo·∫°i c√¢u h·ªèi
            question_type = self.llm.classify_question(question)
            
            has_data = (self.daily_report_data is not None or self.raw_data is not None)
            has_image = os.path.exists(self.current_image_path)
            
            if not has_data and not has_image:
                return "‚ùì Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ tr·∫£ l·ªùi. Vui l√≤ng t·∫£i d·ªØ li·ªáu l√™n."
            
            # X·ª≠ l√Ω theo lo·∫°i c√¢u h·ªèi
            if question_type == "image" and has_image:
                # C√¢u h·ªèi v·ªÅ ·∫£nh - ch·ªâ ph√¢n t√≠ch ·∫£nh
                try:
                    image_analysis = self.llm.analyze_image_with_text(self.current_image_path, question)
                    return f"üìä **Ph√¢n t√≠ch dashboard:**\n{image_analysis}"
                except Exception as e:
                    return f"‚ö†Ô∏è L·ªói ph√¢n t√≠ch ·∫£nh: {str(e)}"
            
            elif question_type == "data" and has_data and self.vector_store:
                # C√¢u h·ªèi v·ªÅ d·ªØ li·ªáu - ch·ªâ ph√¢n t√≠ch d·ªØ li·ªáu
                try:
                    retriever = self.vector_store.as_retriever(search_kwargs={"k": 5})
                    relevant_docs = retriever.get_relevant_documents(question)
                    
                    if relevant_docs:
                        context = "\n\n".join([doc.page_content for doc in relevant_docs])
                        
                        enhanced_prompt = f"""
                        B·∫°n l√† m·ªôt chuy√™n gia ph√¢n t√≠ch d·ªØ li·ªáu kinh doanh. 
                        D·ª±a tr√™n d·ªØ li·ªáu sau, h√£y tr·∫£ l·ªùi c√¢u h·ªèi m·ªôt c√°ch chi ti·∫øt v√† ch√≠nh x√°c:
                        
                        D·ªØ li·ªáu: {context}
                        
                        C√¢u h·ªèi: {question}
                        
                        Y√™u c·∫ßu:
                        - Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát
                        - ƒê∆∞a ra s·ªë li·ªáu c·ª• th·ªÉ
                        - Ph√¢n t√≠ch ng·∫Øn g·ªçn v√† r√µ r√†ng
                        - N·∫øu c√≥ so s√°nh, h√£y l√†m r√µ
                        """
                        
                        data_analysis = self.llm._call(enhanced_prompt)
                        return f"üìà **Ph√¢n t√≠ch d·ªØ li·ªáu:**\n{data_analysis}"
                    else:
                        return "‚ùì Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu ph√π h·ª£p v·ªõi c√¢u h·ªèi."
                        
                except Exception as e:
                    return f"‚ö†Ô∏è L·ªói ph√¢n t√≠ch d·ªØ li·ªáu: {str(e)}"
            
            else:
                # Fallback - th·ª≠ c·∫£ hai n·∫øu kh√¥ng ph√¢n lo·∫°i ƒë∆∞·ª£c r√µ
                response_parts = []
                
                if has_image:
                    try:
                        image_analysis = self.llm.analyze_image_with_text(self.current_image_path, question)
                        response_parts.append(f"üìä **Ph√¢n t√≠ch dashboard:**\n{image_analysis}")
                    except Exception as e:
                        response_parts.append(f"‚ö†Ô∏è L·ªói ph√¢n t√≠ch ·∫£nh: {str(e)}")
                
                if has_data and self.vector_store:
                    try:
                        retriever = self.vector_store.as_retriever(search_kwargs={"k": 3})
                        relevant_docs = retriever.get_relevant_documents(question)
                        
                        if relevant_docs:
                            context = "\n\n".join([doc.page_content for doc in relevant_docs])
                            
                            enhanced_prompt = f"""
                            D·ª±a tr√™n d·ªØ li·ªáu sau, tr·∫£ l·ªùi c√¢u h·ªèi b·∫±ng ti·∫øng Vi·ªát:
                            
                            D·ªØ li·ªáu: {context}
                            
                            C√¢u h·ªèi: {question}
                            
                            Tr·∫£ l·ªùi ng·∫Øn g·ªçn, r√µ r√†ng v·ªõi s·ªë li·ªáu c·ª• th·ªÉ.
                            """
                            
                            data_analysis = self.llm._call(enhanced_prompt)
                            response_parts.append(f"üìà **Ph√¢n t√≠ch d·ªØ li·ªáu:**\n{data_analysis}")
                        
                    except Exception as e:
                        response_parts.append(f"‚ö†Ô∏è L·ªói ph√¢n t√≠ch d·ªØ li·ªáu: {str(e)}")
                
                if response_parts:
                    return "\n\n".join(response_parts)
                else:
                    return "‚ùì Kh√¥ng t√¨m th·∫•y th√¥ng tin ph√π h·ª£p."
            
        except Exception as e:
            return f"‚ùå L·ªói: {str(e)}"

def create_interface():
    qa_system = QASystem()
    
    def process_csv(file, is_raw):
        if file:
            result = qa_system.process_csv_file(file.name, is_raw)
            # C·∫≠p nh·∫≠t summary sau khi t·∫£i d·ªØ li·ªáu
            new_summary = qa_system.get_data_summary()
            return result, new_summary
        return "Ch∆∞a ch·ªçn file", qa_system.get_data_summary()
    
    def process_image_upload(file):
        if file:
            status, image_path = qa_system.process_image(file.name)
            new_summary = qa_system.get_data_summary()
            return status, image_path, new_summary
        return "Ch∆∞a ch·ªçn ·∫£nh", None, qa_system.get_data_summary()
    
    def get_default_image():
        if os.path.exists("data/test1.png"):
            return "data/test1.png"
        elif os.path.exists("test1.png"):
            return "test1.png"
        return None
    
    def get_initial_status():
        """L·∫•y tr·∫°ng th√°i ban ƒë·∫ßu c·ªßa d·ªØ li·ªáu ƒë√£ load"""
        status = []
        
        # Check daily report
        if qa_system.daily_report_data is not None:
            status.append(f"‚úÖ Daily Report: {len(qa_system.daily_report_data)} d√≤ng")
        else:
            status.append("‚ùå Daily Report: Ch∆∞a t·∫£i")
        
        # Check raw data
        if qa_system.raw_data is not None:
            status.append(f"‚úÖ Raw Data: {len(qa_system.raw_data)} d√≤ng")
        else:
            status.append("‚ùå Raw Data: Ch∆∞a t·∫£i")
        
        # Check image
        if os.path.exists(qa_system.current_image_path):
            status.append(f"‚úÖ ·∫¢nh: {qa_system.current_image_path}")
        else:
            status.append("‚ùå ·∫¢nh: Kh√¥ng t√¨m th·∫•y")
        
        return "\n".join(status)
    
    def chat_fn(message, history):
        response = qa_system.answer_question(message)
        history.append([message, response])
        return history, ""
    
    with gr.Blocks(title="QA System", theme=gr.themes.Soft()) as app:
        gr.Markdown("# ü§ñ QA System v·ªõi Ph√¢n t√≠ch Th√¥ng minh")
        
        with gr.Row():
            with gr.Column(scale=1):
                # Image display v·ªõi kh·∫£ nƒÉng upload
                image_display = gr.Image(
                    value=get_default_image(),
                    label="üìä Dashboard", 
                    height=400,
                    interactive=False
                )
                
                # Upload ·∫£nh m·ªõi
                with gr.Accordion("üì∑ Thay ƒë·ªïi ·∫£nh", open=False):
                    with gr.Row():
                        image_upload = gr.File(
                            label="T·∫£i ·∫£nh m·ªõi", 
                            file_types=[".png", ".jpg", ".jpeg"],
                            scale=3
                        )
                        upload_img_btn = gr.Button("üì∑ T·∫£i ·∫£nh", scale=1)
                    
                    img_status = gr.Textbox(
                        label="Tr·∫°ng th√°i ·∫£nh", 
                        interactive=False,
                        value=f"S·ª≠ d·ª•ng ·∫£nh: {qa_system.current_image_path}" if os.path.exists(qa_system.current_image_path) else "Ch∆∞a c√≥ ·∫£nh"
                    )
                
                with gr.Accordion("üìä T·∫£i d·ªØ li·ªáu m·ªõi", open=False):
                    # Hi·ªÉn th·ªã tr·∫°ng th√°i d·ªØ li·ªáu ƒë√£ load
                    gr.Textbox(
                        label="üìã D·ªØ li·ªáu hi·ªán t·∫°i",
                        value=get_initial_status(),
                        interactive=False,
                        lines=4
                    )
                    
                    gr.Markdown("---")
                    
                    with gr.Accordion("üìà Daily Report", open=False):
                        daily_upload = gr.File(label="Ch·ªçn file CSV", file_types=[".csv"])
                        daily_btn = gr.Button("üì§ T·∫£i Daily Report")
                        daily_status = gr.Textbox(label="K·∫øt qu·∫£", interactive=False)
                    
                    with gr.Accordion("üìä Raw Data", open=False):
                        raw_upload = gr.File(label="Ch·ªçn file CSV", file_types=[".csv"])
                        raw_btn = gr.Button("üì§ T·∫£i Raw Data")
                        raw_status = gr.Textbox(label="K·∫øt qu·∫£", interactive=False)
            
            with gr.Column(scale=1):
                # Component Summary m·ªõi
                with gr.Accordion("üìã T·ªïng quan d·ªØ li·ªáu", open=True):
                    data_summary = gr.Markdown(
                        value=qa_system.get_data_summary(),
                        label="T√≥m t·∫Øt d·ªØ li·ªáu"
                    )
                
                # Chatbot
                chatbot = gr.Chatbot(height=350, label="üí¨ Tr√≤ chuy·ªán")
                
                with gr.Row():
                    msg = gr.Textbox(
                        placeholder="Nh·∫≠p c√¢u h·ªèi (h·ªá th·ªëng s·∫Ω t·ª± ƒë·ªông ph√¢n lo·∫°i c√¢u h·ªèi v·ªÅ ·∫£nh hay d·ªØ li·ªáu)...", 
                        container=False, 
                        scale=5
                    )
                    send_btn = gr.Button("üì§ G·ª≠i", scale=1)
                
                clear = gr.Button("üóëÔ∏è X√≥a l·ªãch s·ª≠")
                
                # Th√™m h∆∞·ªõng d·∫´n
                gr.Markdown("""
                **üí° H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng:**
                - C√¢u h·ªèi v·ªÅ **·∫£nh/dashboard**: "·∫¢nh n√†y hi·ªÉn th·ªã g√¨?", "M√†u s·∫Øc trong bi·ªÉu ƒë·ªì", "Giao di·ªán nh∆∞ th·∫ø n√†o?"
                - C√¢u h·ªèi v·ªÅ **d·ªØ li·ªáu**: "T·ªïng volume l√† bao nhi√™u?", "BU n√†o c√≥ doanh thu cao nh·∫•t?", "So s√°nh target v√† actual"
                """)
        
        # Event handlers
        upload_img_btn.click(
            fn=process_image_upload,
            inputs=image_upload,
            outputs=[img_status, image_display, data_summary]
        )
        
        daily_btn.click(
            fn=lambda f: process_csv(f, False),
            inputs=daily_upload,
            outputs=[daily_status, data_summary]
        )
        
        raw_btn.click(
            fn=lambda f: process_csv(f, True),
            inputs=raw_upload,
            outputs=[raw_status, data_summary]
        )
        
        msg.submit(chat_fn, [msg, chatbot], [chatbot, msg])
        send_btn.click(chat_fn, [msg, chatbot], [chatbot, msg])
        clear.click(lambda: [], outputs=chatbot)
    
    return app

if __name__ == "__main__":
    app = create_interface()
    app.launch(
        share=True,
        server_name="0.0.0.0",
        server_port=7860
    )